---
title: "p8105_hw5_fx2212"
author: "Fenglin Xie"
date: "2025-11-08"
output: github_document
---
```{r}
library(tidyverse)
library(broom)
```

## Problem 1

### Function to check for duplicate birthdays in a group
```{r}

check_birthday_duplicates = function(n_room) {
  
  birthdays = sample(1:365, n_room, replace = TRUE)
  
  repeated_bday = length(unique(birthdays)) < n_room
  
  repeated_bday
  
}

```

### Run simulation for group sizes 2 to 50
```{r}
birthday_simulation =
  expand_grid(
    n_room = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(n_room, check_birthday_duplicates)
  ) |> 
  group_by(
    n_room
  ) |> 
  summarize(
    prob_repeat = mean(result)
  )

```

### Plot the results
```{r}
birthday_plot = 
  birthday_simulation |> 
  ggplot(aes(x = n_room, y = prob_repeat)) +
  geom_point() +
  geom_line()

birthday_plot
```

### Comment on results
The probability of shared birthdays increases with group size, reaching approximately 0.5 at group size 23 and over 0.97 at group size 50. This demonstrates the counterintuitive nature of the birthday paradox - it takes far fewer people than most would expect to have a high probability of shared birthdays.


## Problem 2

### Run simulation for different mu values

```{r}
# Function to generate sample data
sample_data = function(mu) {
  tibble(
    x = rnorm(n = 30, mean = mu, sd = 5)
  )
}

# Function to run t-test and return tidy results
run_ttest = function(data) {
  test_result = t.test(data$x, mu = 0)
  broom::tidy(test_result)
}

# Run simulation for different mu values
power_simulation_results =
  expand_grid(
    mu = c(0, 1, 2, 3, 4, 5, 6),
    iter = 1:5000
  ) |> 
  mutate(
    data = map(mu, sample_data),
    test_result = map(data, run_ttest)
  ) |> 
  unnest(test_result)

```

### Calculate summary statistics for each mu

```{r}
power_summary = power_simulation_results |> 
  group_by(mu) |> 
  summarise(
    power = mean(p.value < 0.05),
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05])
  )
```

### Plot 1: Power vs Effect Size

```{r}
power_plot = power_summary |> 
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power Analysis for One-Sample T-Test",
    x = "True Mean (μ)",
    y = "Power (Probability of Rejecting H₀)"
  ) +
  theme_minimal()

power_plot
```

Association between effect size and power: There is a strong positive relationship between effect size (true μ) and power. As the true mean increases from 0 to 6, power increases from approximately `r round(power_summary$power[1], 3)` to `r round(power_summary$power[7], 3)`. This makes sense because larger effect sizes are easier to detect with statistical tests.

### Plot 2: Average Estimates

```{r}
estimate_plot = power_summary |> 
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_line(aes(y = avg_estimate_rejected, color = "Rejected Samples")) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
  labs(
    title = "Average Estimates vs True Mean",
    x = "True Mean (μ)",
    y = "Average Estimate (μ̂)",
    color = "Sample Type"
  ) +
  theme_minimal()

estimate_plot
```

Comparison of estimates: The sample average of μ̂ across tests for which the null is rejected is not equal to the true value of μ, especially for smaller effect sizes. This occurs because when the null is rejected for smaller true means, it's often due to sampling variability that resulted in larger observed effect sizes. This is known as the "winner's curse" in statistical inference - when we only look at significant results, we tend to overestimate the true effect size.

## Problem 3

### Load and prepare data

```{r}

homicide_data = read_csv("homicide-data.csv") |> 
  mutate(
    city_state = str_c(city, ", ", state)
  ) |> 
  filter(city_state != "Tulsa, AL")
```

Remove incorrect entry: Tulsa, AL (Tulsa is actually in Oklahoma, not Alabama), thus this data may not valid.

### Summarize homicide data

```{r}

homicide_summary = homicide_data |> 
  group_by(city_state) |> 
  summarise(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```

Data description: The raw homicide data contains information about homicides in 50 large U.S. cities, including details about victims, locations, and case dispositions. After creating the `city_state` variable and summarizing, we have data on `r nrow(homicide_summary)` cities with total homicides ranging from `r min(homicide_summary$total_homicides)` to `r max(homicide_summary$total_homicides)`. 


# Baltimore analysis
```{r}

baltimore_data = homicide_summary |> 
  filter(city_state == "Baltimore, MD")

baltimore_test = prop.test(
  x = baltimore_data$unsolved_homicides,
  n = baltimore_data$total_homicides
) |> 
  broom::tidy()
```

Baltimore results: For Baltimore, MD, the estimated proportion of unsolved homicides is `r round(baltimore_test$estimate, 3)` with a 95% confidence interval of [`r round(baltimore_test$conf.low, 3)`, `r round(baltimore_test$conf.high, 3)`].


# Analysis for all cities using tidy approach

```{r}
run_prop_test = function(unsolved_homicides, total_homicides) {
  prop_test = prop.test(
    x = unsolved_homicides, 
    n = total_homicides)
  broom::tidy(prop_test)
}

all_cities_test = 
  homicide_summary |> 
  mutate(
    test_results = map2(unsolved_homicides, total_homicides, run_prop_test)
  ) |> 
  unnest(test_results) |> 
  select(city_state, total_homicides, unsolved_homicides, 
         estimate, conf.low, conf.high)
```

### Create plot
```{r}
homicide_plot = all_cities_test |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point(size = 1.5) +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), 
                width = 0.2,
                alpha = 0.7) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    subtitle = "Cities ordered by proportion of unsolved homicides",
    x = "Proportion Unsolved (with 95% CI)",
    y = "City"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 6),
    plot.title = element_text(face = "bold"),
    panel.grid.major.y = element_line(color = "grey90")
  )

homicide_plot
```

